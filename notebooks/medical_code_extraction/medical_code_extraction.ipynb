{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357fe949-7e56-46fe-9e65-83b4bb4b3c66",
   "metadata": {
    "collapsed": false,
    "name": "md_intro"
   },
   "source": [
    "# LLM Assisted Medical Coding Extraction for Healthcare\n",
    "\n",
    "Traditionally, healthcare providers have relied on various tools and methodologies to estimate patient risk scores. However, these conventional methods often fall short in addressing the complexity and variability inherent in patient data. \n",
    "\n",
    "In this notebook, we will show you how to leverage an LLM and implement a [distillation flow](https://www.datacamp.com/blog/distillation-llm) with a Llama 405b model to generate training samples to teach a smaller model the code extraction task with the same accuracy but lower cost.\n",
    "\n",
    "LLM distillation focuses on replicating the performance of a large model on a specific task by transferring its capabilities to a smaller model. This allows developers to achieve similar results to models like GPT-4 but with reduced computational cost and faster performance—though only for the targeted task.\n",
    "\n",
    "In the notebook, we will show you how to fine-tune an LLM using [Cortex Fine-tuning](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-finetuning) to help extract ICD10 codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ef10f-4efe-44a8-ac8d-21b59272cb43",
   "metadata": {
    "collapsed": false,
    "name": "md_import_packages"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "import_packages"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ab17a-eaf9-424f-8088-f9d19b7354f0",
   "metadata": {
    "collapsed": false,
    "name": "md_ingest_chunk"
   },
   "source": [
    "# Data Engineering\n",
    "\n",
    "Let's take a look at the synthetic medical files (PDFs) we'll be using for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b4b75-3162-421b-a30b-16c121fcfbdf",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "show_dir"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DIRECTORY(@PUBLIC.REPORTS_DATA);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01954869-8317-47a5-817c-e185b14e0344",
   "metadata": {
    "collapsed": false,
    "name": "md_parse_chunk"
   },
   "source": [
    "Now, we can use Snowflake's native Cortex AI functions ([PARSE_DOCUMENT](https://docs.snowflake.com/en/sql-reference/functions/parse_document-snowflake-cortex) and [SPLIT_TEXT_RECURSIVE_CHARACTER](https://docs.snowflake.com/en/sql-reference/functions/split_text_recursive_character-snowflake-cortex)) to read/parse the PDFs and chunk the data. Text is chunked into sections for easier processing, allowing overlap for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d705b0-2319-41d4-b702-a44cbb5d7dd6",
   "metadata": {
    "language": "sql",
    "name": "md_docs_chunked"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE DOCS_CHUNKS_TABLE AS\n",
    "    SELECT\n",
    "        RELATIVE_PATH, \n",
    "        SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(\n",
    "            to_variant(SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n",
    "                @PUBLIC.REPORTS_DATA,\n",
    "                RELATIVE_PATH,\n",
    "                {'mode': 'layout'}\n",
    "            )):content, 'markdown', 4000, 400) as chunks\n",
    "from DIRECTORY(@PUBLIC.REPORTS_DATA);\n",
    "\n",
    "CREATE OR REPLACE TABLE DOCS_CHUNKS_TABLE AS\n",
    "SELECT RELATIVE_PATH, c.value::string as CHUNK \n",
    "FROM DOCS_CHUNKS_TABLE f, \n",
    "    LATERAL FLATTEN(INPUT => f.chunks) c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018981f-e412-4445-8d22-de8c86434b89",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "docs_chunks_table"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DOCS_CHUNKS_TABLE;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff7906-3441-4a78-8438-29aba337dde2",
   "metadata": {
    "collapsed": false,
    "name": "md_num_chunks"
   },
   "source": [
    "Let's see the number of chunks created per doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd58774-0555-4a4d-8a16-6998a511fb01",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "group_numofchunks"
   },
   "outputs": [],
   "source": [
    "SELECT RELATIVE_PATH, COUNT(*) AS NUM_CHUNKS\n",
    "FROM DOCS_CHUNKS_TABLE\n",
    "GROUP BY RELATIVE_PATH\n",
    "ORDER BY NUM_CHUNKS DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c75852-f2f7-43f7-8eae-5addb4fe89c1",
   "metadata": {
    "collapsed": false,
    "name": "md_docs_text"
   },
   "source": [
    "Now, let's create a table to store the needed metadata and create a few columns we will populate subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6b30e-303e-4e95-a936-e7be06fa8907",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "docs_and_text"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TRANSIENT TABLE DOCS_AND_TEXT AS\n",
    "SELECT\n",
    "    RELATIVE_PATH,\n",
    "    LISTAGG(CHUNK, ' ') AS DOC_TEXT,\n",
    "    NULL AS REPORT,\n",
    "    NULL AS SPECIALTY\n",
    "FROM DOCS_CHUNKS_TABLE\n",
    "WHERE RELATIVE_PATH LIKE '%.pdf'\n",
    "GROUP BY ALL;\n",
    "\n",
    "select * from docs_and_text limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21007b19-5813-41ea-aab7-1be48ce852dc",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "base_table"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DOCS_AND_TEXT;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c5fe1-1274-4d3d-94a0-a6c1903925df",
   "metadata": {
    "collapsed": false,
    "name": "md_extract_info"
   },
   "source": [
    "Now, we can extract the `speciality` and the `report summary` using Snowflake's native LLM function, Complete(https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex), for LLM-assisted completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf84c56-649f-4137-8f12-e0dbe4eaad74",
   "metadata": {
    "language": "sql",
    "name": "update_speciality"
   },
   "outputs": [],
   "source": [
    "UPDATE DOCS_AND_TEXT AS L\n",
    "SET L.REPORT = R.REPORT,\n",
    "    L.SPECIALTY = R.SPECIALTY\n",
    "FROM (\n",
    "    SELECT\n",
    "        RELATIVE_PATH,\n",
    "        SNOWFLAKE.CORTEX.COMPLETE('llama3.1-8b', CONCAT(DOC_TEXT, 'In less than 5 words, how would you best describe the type of the document content?  Do not provide explanation. Remove special characters.')) AS REPORT,\n",
    "        SNOWFLAKE.CORTEX.COMPLETE('llama3.1-8b', CONCAT(DOC_TEXT, 'What is the medical specialty? Do not provide explanation. Remove special characters.')) AS SPECIALTY\n",
    "    FROM DOCS_AND_TEXT\n",
    ") AS R\n",
    "WHERE L.RELATIVE_PATH = R.RELATIVE_PATH;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1981ba-e45e-494a-98d4-98a37dfd5d8e",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "docs_and_text_speciality"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DOCS_AND_TEXT LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b4e4f-fbb8-4e6e-8fa5-a39d8c62b9d6",
   "metadata": {
    "collapsed": false,
    "name": "md_fine_tuning"
   },
   "source": [
    "# Fine-tuning using `llama3.1-405B`\n",
    "\n",
    "The model `llama3.1-405b` is used to extract ICD-10 codes from medical documents by prompting Snowflake Cortex Complete to identify relevant codes. Outputs are stored in a table called `LLAMA_OUTPUT_ICD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba8004-cc59-44c3-b3a0-37438274e45c",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "distillation_flow_with_largemodel"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE LLAMA_OUTPUT_ICD AS\n",
    "SELECT\n",
    "    RELATIVE_PATH,\n",
    "    DOC_TEXT,\n",
    "    REPORT,\n",
    "    SPECIALTY,\n",
    "    SNOWFLAKE.CORTEX.COMPLETE('llama3.1-405b', CONCAT(DOC_TEXT, 'Given this medical transcript, list the unique major ICD10-CM diagnosis code in this format ONLY: X##.#. Please provide the response in the form of a list ONLY: []. DO NOT include any other text.')) AS AI_ICD10_CODE\n",
    "FROM DOCS_AND_TEXT;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff28a79-b2b6-4bef-873d-13fdb2184f4d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "llama_icd_largemodel"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM LLAMA_OUTPUT_ICD;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635b754-cdd4-4592-bc55-fa676c7d62b3",
   "metadata": {
    "collapsed": false,
    "name": "md_splitdataset"
   },
   "source": [
    "### Prepare the fine-tuning data\n",
    "\n",
    "Let's split our data 70:30 as train/validation sets (common in model training workflows) for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8fd96-15d5-4538-a0ca-c557d502cbdf",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "split_dataset"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TEMPORARY TABLE TEMP_SPLIT_TABLE AS\n",
    "WITH NUMBERED_ROWS AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        ROW_NUMBER() OVER (ORDER BY RANDOM()) AS ROW_NUM,\n",
    "        COUNT(*) OVER() AS TOTAL_ROWS\n",
    "    FROM LLAMA_OUTPUT_ICD\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    CASE\n",
    "        WHEN ROW_NUM < TOTAL_ROWS * 0.7 THEN 'train'\n",
    "        WHEN ROW_NUM > TOTAL_ROWS * 0.7 AND ROW_NUM <= TOTAL_ROWS * 0.85 THEN 'val'\n",
    "        ELSE 'test'\n",
    "    END AS SPLIT\n",
    "FROM NUMBERED_ROWS;\n",
    "\n",
    "CREATE OR REPLACE TABLE CODEEXTRACTION_TRAINING AS\n",
    "SELECT\n",
    "    RELATIVE_PATH,\n",
    "    DOC_TEXT,\n",
    "    REPORT,\n",
    "    SPECIALTY,\n",
    "    AI_ICD10_CODE\n",
    "FROM TEMP_SPLIT_TABLE\n",
    "WHERE SPLIT = 'train';\n",
    "\n",
    "CREATE OR REPLACE TABLE CODEEXTRACTION_TEST AS\n",
    "SELECT\n",
    "    RELATIVE_PATH,\n",
    "    DOC_TEXT,\n",
    "    REPORT,\n",
    "    SPECIALTY,\n",
    "    AI_ICD10_CODE\n",
    "FROM TEMP_SPLIT_TABLE\n",
    "WHERE SPLIT = 'test';\n",
    "\n",
    "CREATE OR REPLACE TABLE CODEEXTRACTION_VAL AS\n",
    "SELECT\n",
    "    RELATIVE_PATH,\n",
    "    DOC_TEXT,\n",
    "    REPORT,\n",
    "    SPECIALTY,\n",
    "    AI_ICD10_CODE\n",
    "FROM TEMP_SPLIT_TABLE\n",
    "WHERE SPLIT = 'val';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64161d2-24a3-48f4-987f-b3eb452ec992",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "sampledata_viewer"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM CODEEXTRACTION_TRAINING LIMIT 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9f152-1600-47ac-9af4-cf4965e862c3",
   "metadata": {
    "collapsed": false,
    "name": "md_baseline"
   },
   "source": [
    "(Optional) If interested, you can also take a look at the baseline output from the smaller model `llama3-8b` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9a3a9-b456-4ce0-87f4-4e70ed426cc0",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "llama38b_ICDOutput_smallmodel"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE LLAMA38B_ICDOUTPUT AS\n",
    "SELECT\n",
    "    RELATIVE_PATH,\n",
    "    DOC_TEXT,\n",
    "    REPORT,\n",
    "    SPECIALTY,\n",
    "    AI_ICD10_CODE,\n",
    "    SNOWFLAKE.CORTEX.COMPLETE('llama3-8b', CONCAT(DOC_TEXT, 'Given this medical transcript, list the unique major ICD10-CM diagnosis code in this format ONLY: X##.#. Please provide the response in the form of a list ONLY: []. DO NOT include any other text.')) AS LLAMA38B_ICD10_CODE\n",
    "FROM LLAMA_OUTPUT_ICD;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534426eb-7066-4018-bee7-ed271c280ba2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "basemodelpromptengineered"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM llama38b_ICDOutput;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b5e56-1550-4348-b9f7-892a8e3aae06",
   "metadata": {
    "collapsed": false,
    "name": "md_start_fine_tuning"
   },
   "source": [
    "### Start the fine-tuning job\n",
    "\n",
    "[Cortex Fine-tuning](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-finetuning) allows users to leverage parameter-efficient fine-tuning (PEFT) to create customized adaptors for use with pre-trained models on more specialized tasks. If you don't want the high cost of training a large model from scratch but need better latency and results than you're getting from prompt engineering or even retrieval augmented generation (RAG) methods, fine-tuning an existing large model is an option. Fine-tuning allows you to use examples to adjust the behavior of the model and improve the model’s knowledge of domain-specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924056b-410b-4582-8120-b6ff24f2ae25",
   "metadata": {
    "language": "sql",
    "name": "md_drop_if_exists"
   },
   "outputs": [],
   "source": [
    "DROP MODEL IF EXISTS FINETUNE_llama38b_ICD10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99149d0d-59c0-4f8c-82da-feb081f488c0",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "FineTuningllama3_8b"
   },
   "outputs": [],
   "source": [
    "SELECT SNOWFLAKE.CORTEX.FINETUNE(\n",
    "    'CREATE', \n",
    "    -- Custom model name, make sure name below is unique\n",
    "    'FINETUNE_llama38b_ICD10',\n",
    "    -- Base model name\n",
    "    'llama3-8b',\n",
    "    -- Training data query\n",
    "    'SELECT doc_text || '' Given this medical transcript, list the unique major ICD10-CM diagnosis code in this format ONLY: X##.#. Please provide the response in the form of a list ONLY: []. DO NOT include any other text. '' AS PROMPT, AI_ICD10_Code AS COMPLETION FROM codeextraction_training',\n",
    "    -- Test data query \n",
    "    'SELECT doc_text || '' Given this medical transcript, list the unique major ICD10-CM diagnosis code in this format ONLY: X##.#. Please provide the response in the form of a list ONLY: []. DO NOT include any other text. '' AS PROMPT, AI_ICD10_Code AS COMPLETION FROM codeextraction_val'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b4a3c-3b6b-4124-867d-b2170f2b71c5",
   "metadata": {
    "collapsed": false,
    "name": "md_replace"
   },
   "source": [
    "# STOP\n",
    "\n",
    "Replace `<>` in the query below with the workflow id returned from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c254e-b9c6-45ab-9488-f844cefdc21d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "describeprocess"
   },
   "outputs": [],
   "source": [
    "-- The output is the job ID of the fine-tuning job:\n",
    "Select SNOWFLAKE.CORTEX.FINETUNE(\n",
    "  'DESCRIBE',\n",
    "'<>');--replace <> with the workflow id returned from the execution of last cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e900a-9800-4e1c-a3c0-74e1219c07fd",
   "metadata": {
    "collapsed": false,
    "name": "md_stop_for_job_finish"
   },
   "source": [
    "# STOP -  PROCEED ONLY WHEN THE STATUS FIELD FOR THE JOB CHANGES TO `FINISHED` IN THE PREVIOUS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350aa1b6-e3f9-4368-a296-fb9ae6417217",
   "metadata": {
    "collapsed": false,
    "name": "md_inference"
   },
   "source": [
    "# Inference with fine-tuned model\n",
    "\n",
    "Now, we can apply our new model to our training data to extract codes from the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a94735-1480-44fd-bb3f-2883079cb71d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "createtable_llama38b_ICD_Code"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE LLAMA38B_ICD_CODES AS\n",
    "SELECT\n",
    "    RELATIVE_PATH,\n",
    "    DOC_TEXT,\n",
    "    REPORT,\n",
    "    SPECIALTY,\n",
    "    SNOWFLAKE.CORTEX.COMPLETE('FINETUNE_llama38b_ICD10', CONCAT(DOC_TEXT, 'Given this medical transcript, list the unique major ICD10-CM diagnosis code in this format ONLY: X##.#. Please provide the response in the form of a list ONLY: []. DO NOT include any other text.')) AS FT_ICD10_CODE\n",
    "FROM CODEEXTRACTION_TRAINING;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8a3c1-c787-46ad-b390-f6f9dc70dcfa",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "llama38b_ICD_Code"
   },
   "outputs": [],
   "source": [
    "llama38b_ICD_Code_FT_df=session.table('llama38b_ICD_Codes').to_pandas()\n",
    "llama38b_ICD_Code_FT_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571b578-c550-4121-9ed8-844c319a8d27",
   "metadata": {
    "collapsed": false,
    "name": "md_conclusion"
   },
   "source": [
    "# Takeaways from using LLM fine-tuning:\n",
    " 1. **HIGHER ACCURACY** from the larger model (run once just for training)\n",
    " 2. **LOWER COST** from using a smaller model in production\n",
    " 3. **HIGH THROUGHPUT** from using a smaller model in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ede212-fb79-429f-9a26-34463cd2978d",
   "metadata": {
    "collapsed": false,
    "name": "md_app"
   },
   "source": [
    "# **Bonus:**\n",
    "You can use Streamlit to visualize using the IDC-10 codes for calculating patient risk scores as a simple interactive app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2e7ab-fc7a-49d1-a92a-1997ba4471df",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "visualize"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "st.title('❄️ Medical Coding Assistant ❄️')\n",
    "st.subheader(\n",
    "    \"\"\"Calculate the risk score accurately by leveraging ICD10 Codes extracted by Fine Tuning a Llama3 with Cortex AI\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Get the current credentials\n",
    "session = get_active_session()\n",
    "reports_df = session.table(\"llama38b_ICD_Codes\").to_pandas()\n",
    "\n",
    "# Fetch ICD codes and descriptions from the Snowflake table\n",
    "def load_icd_data():\n",
    "    codes = list(set(sum([x.split(\"\\n\") for x in reports_df['FT_ICD10_CODE'].tolist()], [])))\n",
    "    cleaned_dict = {}\n",
    "    for line in codes:\n",
    "        match = re.match(r\"^\\[(.*?)\\]\\s*-?\\s*(.*)$\", line)\n",
    "        if match:\n",
    "            code = match.group(1)\n",
    "            description = match.group(2)\n",
    "            if description:  # Only add if description is not empty\n",
    "                cleaned_dict[code] = description\n",
    "    return cleaned_dict\n",
    "\n",
    "cleaned_dict = load_icd_data()\n",
    "\n",
    "def calculate_risk_score(icd_code):\n",
    "    \"\"\"Calculates a random risk score for a given ICD code.\"\"\"\n",
    "    return np.random.rand(1)[0] * 10\n",
    "\n",
    "@st.cache_data\n",
    "def create_patient_dataframe(cleaned_dict):\n",
    "    patient_data = {\n",
    "        'patient_id': [1, 2, 3, 4, 5],\n",
    "        'name': ['Ava Lee', 'Jane Smith', 'Alice Johnson', 'Ella Rose', 'Riley Green'],\n",
    "        'age': [45, 62, 30, 50, 40]\n",
    "    }\n",
    "    patient_df = pd.DataFrame(patient_data)\n",
    "    patient_df['icd_code'] = [random.choice(list(cleaned_dict.keys())) for _ in range(len(patient_df))]\n",
    "    patient_df['risk_score'] = patient_df['icd_code'].apply(calculate_risk_score)\n",
    "    return patient_df\n",
    "\n",
    "patient_df = create_patient_dataframe(cleaned_dict)\n",
    "\n",
    "def display_icd_code_with_explanation(icd_code):\n",
    "    \"\"\"Displays the ICD code with its description.\"\"\"\n",
    "    explanation = cleaned_dict.get(icd_code, 'Explanation not available')\n",
    "    return f\"ICD Code: {icd_code} - {explanation}\"\n",
    "\n",
    "# Select a patient by name\n",
    "patient_name = st.selectbox(\"Select Patient\", patient_df['name'])\n",
    "\n",
    "# Get the selected patient’s data\n",
    "selected_patient = patient_df[patient_df['name'] == patient_name].iloc[0]\n",
    "patient_icd_code = selected_patient['icd_code']\n",
    "patient_risk_score = selected_patient['risk_score']\n",
    "\n",
    "# Display ICD code and risk score\n",
    "st.write(\"---\")\n",
    "st.subheader(display_icd_code_with_explanation(patient_icd_code))\n",
    "st.write(f\"**Risk Score:** {patient_risk_score:.2f}\")\n",
    "st.write(\"---\")\n",
    "\n",
    "# Associated Medical Reports section\n",
    "st.subheader(\"Associated Medical Reports\")\n",
    "\n",
    "# Filter reports based on the patient's ICD code\n",
    "filtered_reports = reports_df[reports_df['FT_ICD10_CODE'].str.contains(patient_icd_code, case=False, na=False)]\n",
    "\n",
    "if not filtered_reports.empty:\n",
    "    with st.expander(f\"View Associated Reports\"):\n",
    "        for idx, report in filtered_reports.iterrows():\n",
    "            st.write(f\"**Report Name:** {report['RELATIVE_PATH']}\")\n",
    "            st.write(f\"**Report Description:** {report['REPORT']}\")\n",
    "            st.write(f\"**Speciality:** {report['SPECIALTY']}\")\n",
    "            st.write(f\"**Extracted Text:** {report['DOC_TEXT']}\")\n",
    "            st.write(\"---\")\n",
    "else:\n",
    "    with st.expander(\"No Reports Found\"):\n",
    "        st.write(\"No associated reports found for this ICD code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "",
   "authorId": "662946542314",
   "authorName": "USER",
   "lastEditTime": 1744751315754,
   "notebookId": "r4cxarijkpl7kaatukya",
   "sessionId": "e8272b44-de6e-471a-b0db-70782187cd64"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
